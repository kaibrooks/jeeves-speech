{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers import Dropout # dropout crew 4 lyf\n",
    "from IPython.display import clear_output # clear plot after each epoch\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt # fancy plots\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime # so we know how much time we've wasted\n",
    "from gtts import gTTS # tts things\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained_models/nietzsche.h5\n",
      "corpus length : 600901\n",
      "unique chars  : 59\n",
      "total patterns: 200287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## use nietzsche, snoop\n",
    "\n",
    "source = 'nietzsche'\n",
    "sfw = False # remove ~~bad words~~\n",
    "\n",
    "\n",
    "## load a model for testing\n",
    "model_path = os.path.join('trained_models',source+'.h5') # load external file\n",
    "model = load_model(model_path)\n",
    "print('Loaded', model_path)\n",
    "\n",
    "## load the corpus\n",
    "path = os.path.join('data',source+'.txt') # path to the corpus\n",
    "\n",
    "with open(path, encoding='utf-8', errors='ignore') as f: # errors=ignore strips non utf-8 chars\n",
    "    text = f.read().lower()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('corpus length :', len(text))\n",
    "print('unique chars  :', len(chars))\n",
    "print('total patterns:', len(sentences))\n",
    "print('') # empty line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "## generate output\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "temperature = 0.5 # 0.5-2ish, higher numbers give more unique output\n",
    "maxChars = 400 # length of new output\n",
    "\n",
    "seed = sentence.replace('\\n','') # cut newlines\n",
    "seed = seed.replace('\\t','')\n",
    "\n",
    "#print('*** seed: <', seed ,'>') # print the seed (text input)\n",
    "#print('\\n',seed, end = '')\n",
    "\n",
    "\n",
    "sys.stdout = open('output.txt', 'w') # use this to output to txt instead of console\n",
    "\n",
    "# make some words\n",
    "for i in range(maxChars):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read generated text\n",
    "f=open(\"output.txt\", \"r\")\n",
    "words = f.read()#.splitlines()\n",
    "\n",
    "# clean up a few lines\n",
    "words = words.replace(\"chorus\", \"\")\n",
    "words = words.replace(\"verse\", \"\")\n",
    "\n",
    "words = words.replace(\" im \", \" i'm \") # spaces give the whole word only\n",
    "\n",
    "if(sfw):\n",
    "    words = words.replace(\"fuck\", \"woof\") # replace fuck with woof\n",
    "    words = words.replace(\"nigga\", \"neezy\")\n",
    "    \n",
    "    \n",
    "# pick a voice\n",
    "if(source == 'nietzsche'):\n",
    "    language = 'en-uk'\n",
    "else:\n",
    "    language = 'en' # fallback\n",
    "    \n",
    "# make tts mp3\n",
    "text = words\n",
    "speech = gTTS(text = text, lang = language, slow = False)\n",
    "speech.save(source+'.mp3')\n",
    "\n",
    "# play it (doesn't do anything in jupyter, needs run through cli)\n",
    "#os.system(\"output.mp3\") # use this in some systems\n",
    "#ffplay output.mp3 # use this in linux?\n",
    "#afplay output.mp3 # macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
